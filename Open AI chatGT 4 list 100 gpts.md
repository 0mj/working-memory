Using Open AI ChatGPT 4 I prompted "List 100 generative pre trained transformers"

OpenAI Models
GPT-1  
GPT-2  
GPT-3  
GPT-3.5  
GPT-4  
Google/DeepMind Models  
BERT (Bidirectional Encoder Representations from Transformers)  
T5 (Text-To-Text Transfer Transformer)  
LaMDA (Language Model for Dialogue Applications)  
Bard (based on PaLM)  
PaLM (Pathways Language Model)  
PaLM 2  
Gemini 1  
Meta (Facebook) Models  
RoBERTa (Robustly Optimized BERT Approach)  
LLaMA (Large Language Model Meta AI)  
LLaMA 2  
OPT (Open Pretrained Transformer)  
Microsoft Models  
Turing-NLG  
Azure OpenAI GPT-based models  
Hugging Face Models  
DistilGPT-2  
Bloom (BigScience Large Open-science Open-access Multilingual Language Model)  
Anthropic  
Claude  
Claude 2  
AI21 Labs  
Jurassic-1  
Jurassic-2  
Other Notable Models  
EleutherAI's GPT-Neo  
GPT-J  
GPT-NeoX  
MosaicML MPT (Mosaic Pretrained Transformer)  
Cohere's Command and Embed models  
OpenAssistant models (LAION initiative)  
Specialized or Domain-Specific Transformers  
BioBERT (Biomedical BERT)  
ClinicalBERT  
FinBERT (Financial BERT)  
CodeBERT (for programming languages)  
Codex (OpenAI's GPT for code)  
DialoGPT (Dialogue GPT for conversational AI)  
ProphetNet (Microsoft for sequence generation)  
CTRL (Conditional Transformer Language)  
Multilingual or Region-Specific Models  
XLM-R (Cross-lingual Language Model by Facebook)  
mBERT (Multilingual BERT)  
CamemBERT (French)  
BETO (Spanish)  
AraBERT (Arabic)  
IndicBERT (Indic languages)  
Fine-Tuned or Task-Specific Variants  
ALBERT (A Lite BERT)  
TinyBERT  
MiniLM  
Pegasus (Text summarization)  
Turing-Bletchley  
Research and Experimental Models  
Megatron-LM (NVIDIA)  
Switch Transformer (Google)  
GShard (Google for scaling)  
WuDao 2.0 (China’s largest model)  
PanGu-Alpha (Huawei)  
Transformers for Vision  
DALL-E (OpenAI for image generation)  
DALL-E 2  
Stable Diffusion (by Stability AI, inspired by transformers)  
Imagen (Google)  
VQ-VAE (Vector Quantized Variational Autoencoder)  
Transformers for Audio  
Whisper (OpenAI for transcription)  
Wav2Vec (Meta)  
Miscellaneous  
Reformer (Efficient transformers)  
Longformer (Efficient for long documents)  
BigBird (Transformer for long sequences)  
PERceiver (Universal model for different modalities)  
TransGAN (Generative Adversarial Networks with transformers)  
AudioLM (Google for audio tasks)  



github.com.copilot Return  
my prompt: "list the top 100 generative pretrained transformers that offer free trials"

1. OpenAI Models
   - GPT-4
   - GPT-3.5
   - GPT-3
   - GPT-2
   - GPT-1

2. Google/DeepMind Models
   - BERT (Bidirectional Encoder Representations from Transformers)
   - T5 (Text-To-Text Transfer Transformer)
   - LaMDA (Language Model for Dialogue Applications)
   - Bard (based on PaLM)
   - PaLM (Pathways Language Model)
   - PaLM 2
   - Gemini 1

3. Meta (Facebook) Models
   - RoBERTa (Robustly Optimized BERT Approach)
   - LLaMA (Large Language Model Meta AI)
   - LLaMA 2
   - OPT (Open Pretrained Transformer)

4. Microsoft Models
   - Turing-NLG
   - Azure OpenAI GPT-based models

5. Hugging Face Models
   - DistilGPT-2
   - Bloom (BigScience Large Open-science Open-access Multilingual Language Model)

6. Anthropic
   - Claude
   - Claude 2

7. AI21 Labs
   - Jurassic-1
   - Jurassic-2

8. Other Notable Models
   - EleutherAI's GPT-Neo
   - GPT-J
   - GPT-NeoX
   - MosaicML MPT (Mosaic Pretrained Transformer)
   - Cohere's Command and Embed models
   - OpenAssistant models (LAION initiative)

9. Specialized or Domain-Specific Transformers
   - BioBERT (Biomedical BERT)
   - ClinicalBERT
   - FinBERT (Financial BERT)
   - CodeBERT (for programming languages)
   - Codex (OpenAI's GPT for code)
   - DialoGPT (Dialogue GPT for conversational AI)
   - ProphetNet (Microsoft for sequence generation)
   - CTRL (Conditional Transformer Language)

10. Multilingual or Region-Specific Models
    - XLM-R (Cross-lingual Language Model by Facebook)
    - mBERT (Multilingual BERT)
    - CamemBERT (French)
    - BETO (Spanish)
    - AraBERT (Arabic)
    - IndicBERT (Indic languages)

11. Fine-Tuned or Task-Specific Variants
    - ALBERT (A Lite BERT)
    - TinyBERT
    - MiniLM
    - Pegasus (Text summarization)
    - Turing-Bletchley

12. Research and Experimental Models
    - Megatron-LM (NVIDIA)
    - Switch Transformer (Google)
    - GShard (Google for scaling)
    - WuDao 2.0 (China’s largest model)
    - PanGu-Alpha (Huawei)

13. Transformers for Vision
    - DALL-E (OpenAI for image generation)
    - DALL-E 2
    - Stable Diffusion (by Stability AI, inspired by transformers)
    - Imagen (Google)
    - VQ-VAE (Vector Quantized Variational Autoencoder)

14. Transformers for Audio
    - Whisper (OpenAI for transcription)
    - Wav2Vec (Meta)

15. Miscellaneous
    - Reformer (Efficient transformers)
    - Longformer (Efficient for long documents)
    - BigBird (Transformer for long sequences)
    - PERceiver (Universal model for different modalities)
    - TransGAN (Generative Adversarial Networks with transformers)
    - AudioLM (Google for audio tasks)

16. Open Source Models
    - GPT-3 Davinci (fine-tuned GPT-3 variant)
    - Falcon (by Technology Innovation Institute)
    - Cerebras-GPT (by Cerebras Systems)
    - EleutherAI's Pythia series (for open-source LLM research)
    - ALICE (Fine-tuned conversational model)

17. Transformers for Education
    - OpenEduChat (education-focused transformer by OpenAI collaborators)
    - EdBERT (educational and pedagogical applications)
    - SQuAD BERT (fine-tuned for reading comprehension tasks)
    - Teacher Assistant GPT (fine-tuned for interactive learning)

18. Transformers in Healthcare
    - MedGPT (medical question-answering applications)
    - PharmBERT (pharmaceutical domain transformer)
    - RadBERT (radiology-specific transformer)
    - PubMedGPT (scientific literature exploration)

19. Transformers for Coding and Development
    - PolyCoder (open-source model for code)
    - TabNine (AI coding assistant powered by GPT)
    - CodeParrot (fine-tuned for GitHub repositories)
    - IntelliCode GPT (Microsoft’s AI developer assistant)

20. Creative and Artistic Transformers
    - ChatGPT (general-purpose conversational AI)
    - Jasper (creative writing and marketing content generator)
    - Writesonic (creative and blog-writing applications)
    - Rytr (AI for creative and professional writing)

21. Language-Specific Models
    - RuGPT (Russian GPT variant)
    - GermEval (German language transformers)
    - PhoBERT (Vietnamese language)
    - MarBERT (Moroccan Arabic and dialects)

22. Experimental Models by Research Labs
    - GLaM (Google’s Generalist Language Model)
    - RETRO (Retrieval-Augmented Transformer by DeepMind)
    - FNet (Fourier Transform-based transformer by Google)
    - TERA (Transformer-based contextual embeddings for speech)

23. Transformers for Scaling and Speed
    - ZeRO (DeepSpeed optimization for large transformers)
    - SparseGPT (efficient sparse transformer variant)
    - GPT-SFT (Supervised Fine-Tuned variant of GPT)
    - DeepSpeed GPT (efficient training for large-scale GPTs)

